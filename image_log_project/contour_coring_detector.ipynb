{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from math import ceil\n",
    "from skimage import feature\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images: list, contours_list: np.array = None, centroids: list = None, n=16):\n",
    "    \n",
    "    images = images[:n]\n",
    "    \n",
    "    n_images = len(images)\n",
    "    n_columns = 4\n",
    "    n_rows = ceil(n_images/n_columns)\n",
    "\n",
    "    x_size = 12\n",
    "    y_size = int( n_rows*x_size/n_columns )\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_columns, figsize=(x_size, y_size), sharex=True, sharey=True)\n",
    "\n",
    "    plt.subplots_adjust(left=0.0,\n",
    "                        bottom=0.0,\n",
    "                        right=1,\n",
    "                        top=1,\n",
    "                        wspace=0.05,\n",
    "                        hspace=0.05)\n",
    "    \n",
    "    ax = axes.flatten()\n",
    "\n",
    "    for axs in ax[n_images:]:\n",
    "        axs.remove()\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        ax[i].set_axis_off()\n",
    "\n",
    "        image = img.copy()\n",
    "        image = image.astype('uint8')\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "        if contours_list is not None:\n",
    "            img_contours = contours_list[i]\n",
    "            cv2.drawContours(image, img_contours, -1, (0, 255, 0), 2)  # -1 means draw all contours, (0, 255, 0) is the color, 2 is the thickness\n",
    "        if centroids is not None:\n",
    "            for cntr in centroids[i]:\n",
    "                cv2.circle(image, cntr, radius=3, color=(0,0,255), thickness=-1)\n",
    "\n",
    "        ax[i].imshow(image)\n",
    "     \n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoringDetector:\n",
    "\n",
    "    def __init__(self, images: np.array) -> None:\n",
    "        self.input_images = images\n",
    "        self.all_transforms = {\"input_images\": self.input_images}\n",
    "\n",
    "    def apply_transforms(\n",
    "        self,\n",
    "        canny_sigma: float = 2.7,\n",
    "        N1: int = 19,\n",
    "        N2: int = 9,\n",
    "        N3: int = 5,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Aplica serie de transformações para encontrar e fechar os contornos\n",
    "        que representam os boreholes.\n",
    "        \"\"\"\n",
    "        images = self.input_images.copy()\n",
    "\n",
    "        # Calcular bordas com canny\n",
    "        images = [feature.canny(img, sigma=canny_sigma) * 255.0 for img in self.input_images]\n",
    "        self.all_transforms[\"canny\"] = images\n",
    "\n",
    "        # Fechar bordas encontradas com fechamento (para criar blobs)\n",
    "        kernel1 = np.ones((N1, N1), np.uint8)\n",
    "        images = [cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel1) for img in images]\n",
    "        self.all_transforms[\"closing\"] = images\n",
    "\n",
    "        # Aplicando abertura com kernel vertical para remover ruidos horizontais\n",
    "        kernel2 = np.ones((N2, 1), np.uint8)\n",
    "        images = [cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel2) for img in images]\n",
    "        self.all_transforms[\"open\"] = images\n",
    "\n",
    "        # Aplicando dilatação para juntar ruidos proximos em grandes regiões, pode facilitar\n",
    "        # na filtragem por área, mas talvez não seja necessario.\n",
    "        kernel3 = np.ones((N3, N3), np.uint8)\n",
    "        images = [cv2.morphologyEx(img, cv2.MORPH_DILATE, kernel3) for img in images]\n",
    "        self.all_transforms[\"dilate\"] = images\n",
    "\n",
    "        return images\n",
    "\n",
    "    @staticmethod\n",
    "    def find_contours(images: list):\n",
    "        \"\"\"\n",
    "        Usa OpenCV para encotrar os blobs\n",
    "        das images pre processadas.\n",
    "        \"\"\"\n",
    "\n",
    "        converted_images = []\n",
    "        for image in np.array(images):\n",
    "            # Ensure that the image is in uint8 format (CV_8U)\n",
    "            if image.max() == 1:\n",
    "                image *= 255\n",
    "            if image.dtype != np.uint8:\n",
    "                image = image.astype(np.uint8)\n",
    "            # Convert to CV_8UC1 format\n",
    "            if len(image.shape) > 2:\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            converted_images.append(image)\n",
    "        \n",
    "        contours = []\n",
    "        for img in converted_images:\n",
    "\n",
    "            contours_list,_ = cv2.findContours(img, cv2.CHAIN_APPROX_SIMPLE, cv2.CHAIN_APPROX_NONE)\n",
    "            contours.append(contours_list)\n",
    "\n",
    "        return contours\n",
    "    \n",
    "    def apply_thresholds(self, contours: np.array, \n",
    "                         min_area : int = 20, \n",
    "                         max_area : int = 400,\n",
    "                         min_round_ratio : float = 0.5,\n",
    "                         max_round_ratio: float = 2.0):\n",
    "        \"\"\"\n",
    "        Filtra thresholds para filtrar contornos com base\n",
    "        em algumas propriedades.\n",
    "        \"\"\"\n",
    "        \n",
    "        filtered_contours = []       \n",
    "        for contours_list in contours:\n",
    "            for contours_list in contours:\n",
    "\n",
    "                new_contours_list = []\n",
    "                for cntr in contours_list:\n",
    "                    \n",
    "                    area = cv2.contourArea(cntr)\n",
    "                    # contour_areas.append(area)\n",
    "\n",
    "                    arclength = cv2.arcLength(cntr, True)\n",
    "                    # arclengths.append(arclength)\n",
    "                    \n",
    "                    round_ratio =  4 * np.pi * area / ( arclength**2 )\n",
    "                    # roundness.append(round_ratio)\n",
    "\n",
    "                    if (round_ratio < max_round_ratio) and (round_ratio > min_round_ratio) and (area > min_area) and (area < max_area):\n",
    "                        new_contours_list.append(cntr)\n",
    "                \n",
    "            \n",
    "                filtered_contours.append(new_contours_list)        \n",
    "\n",
    "        return filtered_contours\n",
    "    \n",
    "    def get_filtered_blobs(self, filtered_contours: list):\n",
    "        \"\"\"\n",
    "        Usa os contornos filtrados para gerar a imges finais\n",
    "        que representam os boreholes.\n",
    "        \"\"\"\n",
    "        \n",
    "        N_images = len(self.input_images)\n",
    "        input_images_shape = (N_images, *(self.input_images[0].shape))\n",
    "        masks = np.zeros(input_images_shape, dtype='uint8')\n",
    "\n",
    "        for i, image in enumerate(masks):\n",
    "                \n",
    "            img_contours = filtered_contours[i]\n",
    "            cv2.drawContours(image, img_contours, -1, (255, 255, 255), cv2.FILLED)  # -1 means draw all contours, (0, 255, 0) is the color, 2 is the thickness\n",
    "    \n",
    "        return masks\n",
    "\n",
    "    @staticmethod\n",
    "    def get_centroids(filtered_contours: list):\n",
    "\n",
    "        centroids = []\n",
    "        for contour_list in filtered_contours:\n",
    "            centroids_list = []\n",
    "            for cntr in contour_list:\n",
    "\n",
    "                M = cv2.moments(cntr)\n",
    "                if M['m00'] > 0:\n",
    "                    cx = int(M['m10']/M['m00'])\n",
    "                    cy = int(M['m01']/M['m00'])\n",
    "                    centroid = np.array([cx, cy])\n",
    "                    centroids_list.append(centroid)\n",
    "            \n",
    "            centroids.append(centroids_list)\n",
    "        \n",
    "        \n",
    "        return centroids\n",
    "\n",
    "    def evaluate_centroids(self, true_centroids, predicted_centroids, threshold=10):\n",
    "\n",
    "        # Asserting compatible lengths to test masks\n",
    "        try:\n",
    "            assert len(true_centroids) == len(predicted_centroids)\n",
    "        except Exception:\n",
    "            print(f\"Mask and contours have incompatible lengths: {len(true_centroids)} and {len(predicted_centroids)}.\")\n",
    "\n",
    "    \n",
    "        true_positives = 0\n",
    "        false_positives = 0\n",
    "        false_negatives = 0\n",
    "\n",
    "        for i in range(len(true_centroids)):\n",
    "            for pred_centroid in predicted_centroids[i]:\n",
    "                match_found = False\n",
    "                for true_centroid in true_centroids[i]:\n",
    "                    distance = np.linalg.norm(pred_centroid-true_centroid)\n",
    "                    if distance < threshold:\n",
    "                        match_found = True\n",
    "                        break\n",
    "                if match_found:\n",
    "                    true_positives += 1\n",
    "                else:\n",
    "                    false_positives += 1\n",
    "                \n",
    "                print(true_positives)\n",
    "\n",
    "        false_negatives = len(true_centroids) - true_positives\n",
    "\n",
    "        precision = true_positives / (true_positives + false_positives)\n",
    "        recall = true_positives / (true_positives + false_negatives)\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "\n",
    "        return precision, recall, f1_score\n",
    "\n",
    "\n",
    "    def evaluate_masks(self, masks_pred : list,\n",
    "                       masks_true : list):\n",
    "        # Asserting compatible lengths to test masks\n",
    "        try:\n",
    "            assert len(masks_pred) == len(masks_true)\n",
    "        except Exception:\n",
    "            print(f\"Mask and contours have incompatible lengths: {len(masks_pred)} and {len(masks_true)}.\")\n",
    "\n",
    "        # Calculating IoU\n",
    "        iou_scores = []\n",
    "        for mask in range(len(masks_pred)):\n",
    "            iou_score = jaccard_score(masks_true[mask], masks_pred[mask], average='micro')\n",
    "            iou_scores.append(iou_score)\n",
    "            \n",
    "        return iou_scores\n",
    "    \n",
    "    def optimize_detector_with_centroids(\n",
    "            self, \n",
    "            train_dataset : list,\n",
    "            centroids_true : list,\n",
    "            transforms_param_grid : list = [{'canny_sigma' : 2.7, 'N1' : 19, 'N2': 9, 'N3' : 5}],\n",
    "            threshold_param_grid : list = [{'min_area': 0.5, 'max_area': 450, 'min_round_ratio': 0.1, 'max_round_ratio': 1.0}]):\n",
    "    \n",
    "        best_tf_params = None\n",
    "        best_ts_params = None\n",
    "        best_score = float('-inf')\n",
    "\n",
    "        for tf_params in tqdm(transforms_param_grid, desc=\"Optmizing Tansforms Parameters Set\", unit=\"param set\"):        \n",
    "            for ts_params in threshold_param_grid:\n",
    "                transformed_images  = self.apply_transforms(**tf_params)\n",
    "                contours = self.find_contours(transformed_images)\n",
    "                filtered_contours = self.apply_thresholds(contours, **ts_params)\n",
    "                centroids_pred = self.get_centroids(filtered_contours)\n",
    "                \n",
    "                _, _, evaluation_metric = self.evaluate_centroids(centroids_true, centroids_pred)\n",
    "    \n",
    "                if evaluation_metric > best_score:\n",
    "                    best_score = evaluation_metric\n",
    "                    best_tf_params = tf_params\n",
    "                    best_ts_params = ts_params\n",
    "\n",
    "        return best_score, best_tf_params, best_ts_params\n",
    "\n",
    "    def optimize_detector(self, train_dataset : list,\n",
    "                                  masks_true : list,\n",
    "                                  transforms_param_grid : list = [{'canny_sigma' : 2.7, 'N1' : 19, 'N2': 9, 'N3' : 5}],\n",
    "                                  threshold_param_grid : list = [{'min_area': 0.5, 'max_area': 450, 'min_round_ratio': 0.1, 'max_round_ratio': 1.0}]):\n",
    "        best_tf_params = None\n",
    "        best_ts_params = None\n",
    "        best_iou_score = float('-inf')\n",
    "\n",
    "        for tf_params in tqdm(transforms_param_grid, desc=\"Optmizing Tansforms Parameters Set\", unit=\"param set\"):        \n",
    "            for ts_params in threshold_param_grid:\n",
    "                transformed_images  = self.apply_transforms(**tf_params)\n",
    "                contours = self.find_contours(transformed_images)\n",
    "                filtered_contours = self.apply_thresholds(contours, **ts_params)\n",
    "                masks_pred = self.get_filtered_blobs(filtered_contours)\n",
    "                \n",
    "                evaluation_metric = self.evaluate_masks(masks_pred, masks_true)\n",
    "                evaluation_mean = np.mean(evaluation_metric)\n",
    "    \n",
    "                if evaluation_mean > best_iou_score:\n",
    "                    best_iou_score = evaluation_mean\n",
    "                    best_tf_params = tf_params\n",
    "                    best_ts_params = ts_params\n",
    "\n",
    "        return best_iou_score, best_tf_params, best_ts_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_dir = '../data/train/image/*'\n",
    "imgs_paths = glob(imgs_dir)\n",
    "imgs_paths = sorted(imgs_paths)\n",
    "\n",
    "\n",
    "# Create list with all images in gray scale\n",
    "images_gray = [ cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) for image_path in imgs_paths]\n",
    "# images_gray = images_gray[:42]\n",
    "# Visualizando imagens\n",
    "# plot_images(images_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = CoringDetector(images_gray[:42])\n",
    "transformed_images  = detector.apply_transforms()\n",
    "contours = detector.find_contours(transformed_images)\n",
    "filtered_contours = detector.apply_thresholds(contours)\n",
    "\n",
    "# Essas são as images usadas para testar contra os dados de treino.\n",
    "blobs = detector.get_filtered_blobs(filtered_contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot_images(blobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for stage in detector.all_transforms:\n",
    "\n",
    "#     print(stage)\n",
    "#     plot_images(detector.all_transforms[stage])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detector parameters optmization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def plot_random_iou(masks_true, masks_preds):\n",
    "    random.seed(42)\n",
    "    \n",
    "    idx = random.sample(range(len(masks_true)),1)[0]\n",
    "\n",
    "    iou_score = jaccard_score(masks_true[idx], masks_preds[idx], average='micro')\n",
    "\n",
    "    plt.imshow(images_gray[idx], cmap='gray')\n",
    "    plt.imshow(masks_true[idx], cmap='Blues', alpha=0.5)\n",
    "    plt.imshow(masks_preds[idx], cmap='Reds', alpha=0.3)\n",
    "    plt.title(\"IoU: {:.2f}\".format(iou_score))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def plot_random_iou_grid(masks_true, masks_preds, grid_size=(5, 5), figsize=(15, 15), save_path=None):\n",
    "    assert len(masks_true) == len(masks_preds), \"Input lists must have the same length\"\n",
    "\n",
    "    random.seed(42)\n",
    "\n",
    "    fig, axes = plt.subplots(*grid_size, figsize=figsize)\n",
    "\n",
    "    for i in range(grid_size[0]):\n",
    "        for j in range(grid_size[1]):\n",
    "            idx = random.randint(0, len(masks_true) - 1)\n",
    "\n",
    "            iou_score = jaccard_score(masks_true[idx], masks_preds[idx], average='micro')\n",
    "\n",
    "            # axes[i, j].imshow(images_gray[idx], cmap='gray')\n",
    "            axes[i, j].imshow(masks_true[idx], cmap='Blues', alpha=0.7)\n",
    "            axes[i, j].imshow(masks_preds[idx], cmap='Reds', alpha=0.5)\n",
    "            axes[i, j].set_title(\"IoU: {:.2f}\".format(iou_score))\n",
    "            axes[i, j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format='pdf', dpi=300)\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_images = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_dir = '../data/train/image/*'\n",
    "imgs_paths = glob(imgs_dir)\n",
    "imgs_paths = sorted(imgs_paths)\n",
    "imgs_paths = imgs_paths[:N_images]\n",
    "\n",
    "train_dataset = [ cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) for image_path in imgs_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "# Padding images to 256x256\n",
    "\n",
    "# Find the maximum shape among all arrays\n",
    "max_shape = max(arr.shape for arr in train_dataset)\n",
    "\n",
    "# Pad or resize each array to the maximum shape\n",
    "padded_arrays = [np.pad(arr, [(0, max_shape[0] - arr.shape[0]), (0, max_shape[1] - arr.shape[1])], mode='constant', constant_values=int(np.mean(arr))) for arr in train_dataset]\n",
    "\n",
    "# Convert the list of arrays to a single NumPy array\n",
    "train_dataset = np.array(padded_arrays)\n",
    "\n",
    "# Check the shape of the resulting array\n",
    "print(train_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_dir = '../data/train/mask/*'\n",
    "masks_paths = glob(masks_dir)\n",
    "masks_paths = sorted(masks_paths)\n",
    "masks_paths = masks_paths[:N_images]\n",
    "\n",
    "# Create list with all images in gray scale\n",
    "masks_gray = [ cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) for mask_path in masks_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "# Padding masks to 256x256 \n",
    "\n",
    "# Find the maximum shape among all arrays\n",
    "max_shape = max(arr.shape for arr in masks_gray)\n",
    "\n",
    "# Pad or resize each array to the maximum shape\n",
    "padded_arrays = [np.pad(arr, [(0, max_shape[0] - arr.shape[0]), (0, max_shape[1] - arr.shape[1])], mode='constant') for arr in masks_gray]\n",
    "\n",
    "# Convert the list of arrays to a single NumPy array\n",
    "train_masks = np.array(padded_arrays)\n",
    "\n",
    "# Get the true centroids for the maks\n",
    "masks_contours = CoringDetector.find_contours(train_masks)\n",
    "masks_centroids = CoringDetector.get_centroids(masks_contours)\n",
    "\n",
    "# plot_images(train_masks, masks_contours, masks_centroids)\n",
    "\n",
    "# Check the shape of the resulting array\n",
    "print(train_masks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create params grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 4 parameters set were created.\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter ranges and steps\n",
    "min_area_range = np.arange(1, 10, 5.)  # from 10 to 50, steps of 10\n",
    "max_area_range = np.arange(400, 450, 50)  # from 250 to 450, steps of 50\n",
    "min_round_ratio_range = np.arange(0.1, 0.2, 0.1)  # from 0.25 to 0.75, steps of 0.125\n",
    "max_round_ratio_range = np.arange(0.5, 1.5, 0.5)  # from 1.0 to 3.0, steps of 0.5\n",
    "\n",
    "# Construct the param_grid\n",
    "ts_param_grid = [\n",
    "    {'min_area': min_area, 'max_area': max_area, 'min_round_ratio': min_round_ratio, 'max_round_ratio': max_round_ratio}\n",
    "    for min_area in min_area_range\n",
    "    for max_area in max_area_range\n",
    "    for min_round_ratio in min_round_ratio_range\n",
    "    for max_round_ratio in max_round_ratio_range\n",
    "]\n",
    "\n",
    "print(f\"A total of {len(ts_param_grid)} parameters set were created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 88 parameters set were created.\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter ranges and steps\n",
    "canny_sigma_range = np.arange(1, 5, 0.5)\n",
    "N1_range = np.arange(11, 32, step=2)\n",
    "N2_fixed = 9\n",
    "N3_fixed = 5\n",
    "\n",
    "# Construct the param_grid\n",
    "tf_param_grid = [\n",
    "    {'canny_sigma': canny_sigma, 'N1': N1, 'N2': N2_fixed, 'N3': N3_fixed}\n",
    "    for canny_sigma in canny_sigma_range\n",
    "    for N1 in N1_range\n",
    "]\n",
    "\n",
    "print(f\"A total of {len(tf_param_grid)} parameters set were created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brute force params optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  optimize using IoU\n",
    "\n",
    "# detector = CoringDetector(train_dataset)\n",
    "# best_score, best_tf_params, best_ts_params = detector.optimize_detector(train_dataset, train_masks, transforms_param_grid=tf_param_grid, threshold_param_grid=ts_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optmizing Tansforms Parameters Set:   0%|          | 0/88 [00:00<?, ?param set/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optmizing Tansforms Parameters Set:   0%|          | 0/88 [00:00<?, ?param set/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask and contours have incompatible lengths: 50 and 2500.\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\antho\\Documents\\sidewall-coring-detection\\image_log_project\\contour_coring_detector.ipynb Cell 23\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#  optimize using f1_score\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m detector \u001b[39m=\u001b[39m CoringDetector(train_dataset)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m best_score, best_tf_params, best_ts_params \u001b[39m=\u001b[39m detector\u001b[39m.\u001b[39;49moptimize_detector_with_centroids(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     train_dataset, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#X30sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     masks_centroids, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#X30sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     transforms_param_grid\u001b[39m=\u001b[39;49mtf_param_grid,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#X30sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     threshold_param_grid\u001b[39m=\u001b[39;49mts_param_grid)\n",
      "\u001b[1;32mc:\\Users\\antho\\Documents\\sidewall-coring-detection\\image_log_project\\contour_coring_detector.ipynb Cell 23\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#X30sZmlsZQ%3D%3D?line=208'>209</a>\u001b[0m filtered_contours \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_thresholds(contours, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mts_params)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#X30sZmlsZQ%3D%3D?line=209'>210</a>\u001b[0m centroids_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_centroids(filtered_contours)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#X30sZmlsZQ%3D%3D?line=211'>212</a>\u001b[0m _, _, evaluation_metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate_centroids(centroids_true, centroids_pred)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#X30sZmlsZQ%3D%3D?line=213'>214</a>\u001b[0m \u001b[39mif\u001b[39;00m evaluation_metric \u001b[39m>\u001b[39m best_score:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#X30sZmlsZQ%3D%3D?line=214'>215</a>\u001b[0m     best_score \u001b[39m=\u001b[39m evaluation_metric\n",
      "\u001b[1;32mc:\\Users\\antho\\Documents\\sidewall-coring-detection\\image_log_project\\contour_coring_detector.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#X30sZmlsZQ%3D%3D?line=169'>170</a>\u001b[0m precision \u001b[39m=\u001b[39m true_positives \u001b[39m/\u001b[39m (true_positives \u001b[39m+\u001b[39m false_positives)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#X30sZmlsZQ%3D%3D?line=170'>171</a>\u001b[0m recall \u001b[39m=\u001b[39m true_positives \u001b[39m/\u001b[39m (true_positives \u001b[39m+\u001b[39m false_negatives)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#X30sZmlsZQ%3D%3D?line=171'>172</a>\u001b[0m f1_score \u001b[39m=\u001b[39m \u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39;49m (precision \u001b[39m*\u001b[39;49m recall) \u001b[39m/\u001b[39;49m (precision \u001b[39m+\u001b[39;49m recall)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#X30sZmlsZQ%3D%3D?line=174'>175</a>\u001b[0m \u001b[39mreturn\u001b[39;00m precision, recall, f1_score\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "#  optimize using f1_score\n",
    "\n",
    "detector = CoringDetector(train_dataset)\n",
    "best_score, best_tf_params, best_ts_params = detector.optimize_detector_with_centroids(\n",
    "    train_dataset, \n",
    "    masks_centroids, \n",
    "    transforms_param_grid=tf_param_grid,\n",
    "    threshold_param_grid=ts_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_score, best_tf_params, best_ts_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detector optimized with best_params\n",
    "optm_detector = CoringDetector(train_dataset)\n",
    "transformed_images  = optm_detector.apply_transforms(**best_tf_params)\n",
    "contours = optm_detector.find_contours(transformed_images)\n",
    "filtered_contours = optm_detector.apply_thresholds(contours, **best_params)\n",
    "\n",
    "optm_blobs = optm_detector.get_filtered_blobs(filtered_contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(optm_blobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_random_iou(train_masks, optm_blobs)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_random_iou_grid(train_masks,optm_blobs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
