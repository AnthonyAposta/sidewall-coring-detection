{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "from skimage import feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoringDetector:\n",
    "\n",
    "    def __init__(self, images: np.array) -> None:\n",
    "        self.input_images = images\n",
    "        self.all_transforms = {\"input_images\": self.input_images}\n",
    "\n",
    "    def apply_transforms(\n",
    "        self,\n",
    "        canny_sigma: float = 2.7,\n",
    "        N1: int = 19,\n",
    "        N2: int = 9,\n",
    "        N3: int = 5,\n",
    "    ):\n",
    "        images = self.input_images.copy()\n",
    "\n",
    "        # Calcular bordas com canny\n",
    "        images = [feature.canny(img, sigma=canny_sigma) * 255.0 for img in self.input_images]\n",
    "        self.all_transforms[\"canny\"] = images\n",
    "\n",
    "        # Fechar bordas encontradas com fechamento (para criar blobs)\n",
    "        kernel1 = np.ones((N1, N1), np.uint8)\n",
    "        images = [cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel1) for img in images]\n",
    "        self.all_transforms[\"closing\"] = images\n",
    "\n",
    "        # Aplicando abertura com kernel vertical para remover ruidos horizontais\n",
    "        kernel2 = np.ones((N2, 1), np.uint8)\n",
    "        images = [cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel2) for img in images]\n",
    "        self.all_transforms[\"open\"] = images\n",
    "\n",
    "        # Aplicando dilatação para juntar ruidos proximos em grandes regiões, pode facilitar\n",
    "        # na filtragem por área, mas talvez não seja necessario.\n",
    "        kernel3 = np.ones((N3, N3), np.uint8)\n",
    "        images = [cv2.morphologyEx(img, cv2.MORPH_DILATE, kernel3) for img in images]\n",
    "        self.all_transforms[\"dialate\"]\n",
    "\n",
    "        return images\n",
    "\n",
    "    def find_contours(self, images: list):\n",
    "\n",
    "        converted_images = []\n",
    "        for image in np.array(images):\n",
    "            # Ensure that the image is in uint8 format (CV_8U)\n",
    "            if image.max() == 1:\n",
    "                image *= 255\n",
    "            if image.dtype != np.uint8:\n",
    "                image = image.astype(np.uint8)\n",
    "            # Convert to CV_8UC1 format\n",
    "            if len(image.shape) > 2:\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            converted_images.append(image)\n",
    "        \n",
    "        contours = []\n",
    "        for img in converted_images:\n",
    "\n",
    "            contours_list,_ = cv2.findContours(img, cv2.CHAIN_APPROX_SIMPLE, cv2.CHAIN_APPROX_NONE)\n",
    "            contours.append(contours_list)\n",
    "\n",
    "        return contours\n",
    "    \n",
    "    def apply_thresholds(self, contours: np.array, \n",
    "                         min_area : int = 20, \n",
    "                         max_area : int = 400,\n",
    "                         min_round_ratio : float = 0.5,\n",
    "                         max_round_ratio: float = 2.0):\n",
    "        \n",
    "        filtered_contours = []       \n",
    "        for contours_list in contours:\n",
    "            for contours_list in contours:\n",
    "\n",
    "                new_contours_list = []\n",
    "                for cntr in contours_list:\n",
    "                    \n",
    "                    area = cv2.contourArea(cntr)\n",
    "                    # contour_areas.append(area)\n",
    "\n",
    "                    arclength = cv2.arcLength(cntr, True)\n",
    "                    # arclengths.append(arclength)\n",
    "                    \n",
    "                    round_ratio =  4 * np.pi * area / ( arclength**2 )\n",
    "                    # roundness.append(round_ratio)\n",
    "\n",
    "                    if (round_ratio > 0.5) and (area > 20) and (area < 400):\n",
    "                        new_contours_list.append(cntr)\n",
    "                \n",
    "            \n",
    "                filtered_contours.append(new_contours_list)\n",
    "        \n",
    "        return filtered_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_dir = '../data/train/image/*'\n",
    "imgs_paths = glob(imgs_dir)\n",
    "imgs_paths = sorted(imgs_paths)\n",
    "\n",
    "\n",
    "# Create list with all images in gray scale\n",
    "images_gray = [ cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) for image_path in imgs_paths]\n",
    "images_gray = images_gray[:42]\n",
    "# Visualizando imagens\n",
    "# plot_images(images_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CoringDetector' object has no attribute 'images'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\antho\\Documents\\sidewall-coring-detection\\image_log_project\\contour_coring_detector.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m detector \u001b[39m=\u001b[39m CoringDetector(images_gray)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m transformed_images  \u001b[39m=\u001b[39m detector\u001b[39m.\u001b[39;49mapply_transforms()\n",
      "\u001b[1;32mc:\\Users\\antho\\Documents\\sidewall-coring-detection\\image_log_project\\contour_coring_detector.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_transforms\u001b[39m(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     canny_sigma: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m2.7\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     N3: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m ):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     images \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimages\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m# Calcular bordas com canny\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antho/Documents/sidewall-coring-detection/image_log_project/contour_coring_detector.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     images \u001b[39m=\u001b[39m [feature\u001b[39m.\u001b[39mcanny(img, sigma\u001b[39m=\u001b[39mcanny_sigma) \u001b[39m*\u001b[39m \u001b[39m255.0\u001b[39m \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_images]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CoringDetector' object has no attribute 'images'"
     ]
    }
   ],
   "source": [
    "detector = CoringDetector(images_gray)\n",
    "transformed_images  = detector.apply_transforms()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image-log-project-dMw6_pq3-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
